{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setting paths for datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "\n",
    "cwd =  os.getcwd()\n",
    "\n",
    "train_path = os.path.join(cwd, 'dataset/combined_5celebs_family/train')\n",
    "validation_path = os.path.join(cwd, 'dataset/combined_5celebs_family/val/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from face_recog.io import ImageDataset\n",
    "\n",
    "data_train = ImageDataset(train_path)\n",
    "X_train, y_train = data_train.load_data(convert_xy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 187\n",
      "Number of labels: 187\n",
      "Label: aditya Shape: (1471, 1140, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Number of images:', len(X_train))\n",
    "print('Number of labels:', len(y_train))\n",
    "\n",
    "for i, x in enumerate(X_train):\n",
    "    print('Label:', y_train[i], 'Shape:', x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creating a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('detector',\n",
       "                 <face_recog.detector.FaceDetectorTransformer object at 0x00000182702D92E8>),\n",
       "                ('face_embedding_transformers',\n",
       "                 <face_recog.recognizer.FacenetEmbeddingsTransformer object at 0x00000182702D3F28>),\n",
       "                ('normalizer', Normalizer(copy=True, norm='l2')),\n",
       "                ('classifier',\n",
       "                 XGBClassifier(base_score=0.5, booster=None,\n",
       "                               colsample_bylevel=1, col...\n",
       "                               interaction_constraints=None,\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=0, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "                               subsample=1, tree_method=None,\n",
       "                               validate_parameters=False, verbosity=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from face_recog.detector import FaceDetectorTransformer\n",
    "from face_recog.recognizer import FacenetEmbeddingsTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "detector = FaceDetectorTransformer(final_size=(160, 160))\n",
    "recognizer = FacenetEmbeddingsTransformer(model_path='models/keras/facenet_keras.h5')\n",
    "norm = Normalizer(norm='l2')\n",
    "clf = XGBClassifier()\n",
    "\n",
    "pipeline = Pipeline([('detector', detector), \n",
    "                     ('face_embedding_transformers', recognizer), \n",
    "                     ('normalizer', norm), \n",
    "                     ('classifier', clf) ])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('detector', <face_recog.detector.FaceDetectorTransformer at 0x182702d92e8>),\n",
       " ('face_embedding_transformers',\n",
       "  <face_recog.recognizer.FacenetEmbeddingsTransformer at 0x182702d3f28>),\n",
       " ('normalizer', Normalizer(copy=True, norm='l2')),\n",
       " ('classifier',\n",
       "  XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "                colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                importance_type='gain', interaction_constraints=None,\n",
       "                learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "                min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "                n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "                objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "                reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "                tree_method=None, validate_parameters=False, verbosity=None))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('detector', <face_recog.detector.FaceDetectorTransformer at 0x182702d92e8>),\n",
       " ('face_embedding_transformers',\n",
       "  <face_recog.recognizer.FacenetEmbeddingsTransformer at 0x182702d3f28>),\n",
       " ('normalizer', Normalizer(copy=True, norm='l2')),\n",
       " ('classifier',\n",
       "  XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "                colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                importance_type='gain', interaction_constraints=None,\n",
       "                learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "                min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "                n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "                objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "                reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "                tree_method=None, validate_parameters=False, verbosity=None))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'detector', 'face_embedding_transformers', 'normalizer', 'classifier', 'normalizer__copy', 'normalizer__norm', 'classifier__objective', 'classifier__base_score', 'classifier__booster', 'classifier__colsample_bylevel', 'classifier__colsample_bynode', 'classifier__colsample_bytree', 'classifier__gamma', 'classifier__gpu_id', 'classifier__importance_type', 'classifier__interaction_constraints', 'classifier__learning_rate', 'classifier__max_delta_step', 'classifier__max_depth', 'classifier__min_child_weight', 'classifier__missing', 'classifier__monotone_constraints', 'classifier__n_estimators', 'classifier__n_jobs', 'classifier__num_parallel_tree', 'classifier__random_state', 'classifier__reg_alpha', 'classifier__reg_lambda', 'classifier__scale_pos_weight', 'classifier__subsample', 'classifier__tree_method', 'classifier__validate_parameters', 'classifier__verbosity'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.steps[1][1].discard_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('face_recog_pipeline.pkl', 'wb') as output:\n",
    "    pickle.dump(pipeline, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 49\n",
      "Number of labels: 49\n",
      "Label: aditya Shape: (837, 1224, 3)\n"
     ]
    }
   ],
   "source": [
    "data_val = ImageDataset(validation_path)\n",
    "X_val, y_val = data_val.load_data(convert_xy=True)\n",
    "\n",
    "print('Number of images:', len(X_val))\n",
    "print('Number of labels:', len(y_val))\n",
    "\n",
    "for i, x in enumerate(X_val):\n",
    "    print('Label:', y_val[i], 'Shape:', x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error finding bounding box for IMG NUM (30): \n",
      " not enough values to unpack (expected 3, got 2)\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.83333333333334 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_val = [v for i, v in enumerate(y_val) if i not in [30]]\n",
    "print('Accuracy:', accuracy_score(y_val, y_pred)*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(837, 1224, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_val[0])\n",
    "X_val[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(face_recog)",
   "language": "python",
   "name": "face_recog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
